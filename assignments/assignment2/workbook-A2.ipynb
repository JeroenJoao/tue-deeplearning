{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment2/workbook-A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7-y662f1PHV"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfUkWhex5pLP"
   },
   "outputs": [],
   "source": [
    "# Install PyTorch Geometric\n",
    "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "!pip install -q torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-3iwORqz9BQJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "import io\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def download(url, filetype='tensor'):\n",
    "    if filetype not in ['tensor', 'pickle', 'json']:\n",
    "        raise ValueError('Incorrect filetype')\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    if filetype == 'tensor':\n",
    "        return torch.load(io.BytesIO(response.content))\n",
    "    elif filetype == 'pickle':\n",
    "        return pickle.load(io.BytesIO(response.content))\n",
    "    elif filetype == 'json':\n",
    "        return json.load(io.BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtLMtRZa1Vjy"
   },
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3h2zBMkm1XpD"
   },
   "outputs": [],
   "source": [
    "## Download the dataset for image retrieval ##\n",
    "data_1 = download('https://surfdrive.surf.nl/files/index.php/s/EH2tN7JiZnwdIXg/download', filetype='tensor')\n",
    "data_metadata = download('https://github.com/pmernyei/wiki-cs-dataset/raw/master/dataset/metadata.json', filetype='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1621940467107,
     "user": {
      "displayName": "Yoeri Poels",
      "photoUrl": "",
      "userId": "12918185417432069249"
     },
     "user_tz": -120
    },
    "id": "rwHKWhIF90JE",
    "outputId": "031a7857-60ba-4acc-9803-e0f98558cf33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num nodes: 10701\n",
      "Num edges: 251927\n",
      "\n",
      "Num node features: 300\n",
      "Num classes: 10\n",
      "\n",
      "Num training labels: 522\n"
     ]
    }
   ],
   "source": [
    "num_node = data_1.x.shape[0]\n",
    "num_edge = data_1.edge_index.shape[1]\n",
    "num_node_feature = data_1.x.shape[1]\n",
    "num_class = int(max(data_1.y)+1)\n",
    "num_label = sum(data_1.train_mask)\n",
    "\n",
    "print(f'Num nodes: {num_node}')\n",
    "print(f'Num edges: {num_edge}')\n",
    "print()\n",
    "print(f'Num node features: {num_node_feature}')\n",
    "print(f'Num classes: {num_class}')\n",
    "print()\n",
    "print(f'Num training labels: {num_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1621940467107,
     "user": {
      "displayName": "Yoeri Poels",
      "photoUrl": "",
      "userId": "12918185417432069249"
     },
     "user_tz": -120
    },
    "id": "ZkCGKmY0CPh2",
    "outputId": "49bf2307-7898-42c2-a95f-97a42a7772fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Computational linguistics\n",
      "1: Databases\n",
      "2: Operating systems\n",
      "3: Computer architecture\n",
      "4: Computer security\n",
      "5: Internet protocols\n",
      "6: Computer file systems\n",
      "7: Distributed computing architecture\n",
      "8: Web technology\n",
      "9: Programming language topics\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_class):\n",
    "    print('{}: {}'.format(i, data_metadata['labels'][str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7pDn_vdhCNPw"
   },
   "outputs": [],
   "source": [
    "def print_node(idx, url=True, label=True):\n",
    "    node_info = data_metadata['nodes'][idx]\n",
    "    print(f'--Node {idx}--')\n",
    "    if url:\n",
    "        title = node_info['title']\n",
    "        wiki_url = 'https://en.wikipedia.org/wiki/' + title\n",
    "        print(wiki_url)\n",
    "    if label:\n",
    "        print('Label:', node_info['label'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1621940467108,
     "user": {
      "displayName": "Yoeri Poels",
      "photoUrl": "",
      "userId": "12918185417432069249"
     },
     "user_tz": -120
    },
    "id": "hvCmB6tFCr4R",
    "outputId": "d692d542-54ad-4706-945c-80a30ca78643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Node 0--\n",
      "https://en.wikipedia.org/wiki/Twilio\n",
      "Label: Distributed computing architecture\n",
      "\n",
      "--Node 1--\n",
      "https://en.wikipedia.org/wiki/Program_compatibility_date_range\n",
      "Label: Operating systems\n",
      "\n",
      "--Node 2--\n",
      "https://en.wikipedia.org/wiki/SYSTAT_(DEC)\n",
      "Label: Operating systems\n",
      "\n",
      "--Node 3--\n",
      "https://en.wikipedia.org/wiki/List_of_column-oriented_DBMSes\n",
      "Label: Databases\n",
      "\n",
      "--Node 4--\n",
      "https://en.wikipedia.org/wiki/Stealth_wallpaper\n",
      "Label: Computer security\n",
      "\n",
      "--Node 5--\n",
      "https://en.wikipedia.org/wiki/Scalable_TCP\n",
      "Label: Internet protocols\n",
      "\n",
      "--Node 6--\n",
      "https://en.wikipedia.org/wiki/Carrier_IQ\n",
      "Label: Computer security\n",
      "\n",
      "--Node 7--\n",
      "https://en.wikipedia.org/wiki/ACF2\n",
      "Label: Operating systems\n",
      "\n",
      "--Node 8--\n",
      "https://en.wikipedia.org/wiki/Dorkbot_(malware)\n",
      "Label: Computer security\n",
      "\n",
      "--Node 9--\n",
      "https://en.wikipedia.org/wiki/Lout_(software)\n",
      "Label: Programming language topics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print_node(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IiWSjUmW1ZQ2"
   },
   "outputs": [],
   "source": [
    "## Build the article retrieval system ##\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_features = int(data_1.x.shape[1])\n",
    "num_classes = int(max(data_1.y)+1)\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_features, hidden_channels)  # the node's word vector (with size num_features) is  \n",
    "                                                              # transformed to a vector of size hidden_channels\n",
    "\n",
    "        self.conv2 = SAGEConv(hidden_channels, num_classes)  # we convert our nodes from hidden_channels to num_classes, the\n",
    "                                                             # last update step turns a node's state into a node-class prediction\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x = (1), all nodes contain information about itself (x_size, num_features)\n",
    "        x = self.conv1(x, edge_index) # x = (2), update all nodes for the first time, returning (x_size, hidden_channels)\n",
    "        x = x.relu()  # activation function\n",
    "        x = F.dropout(x, p=0.7, training=self.training)  # attempt to combat overfitting, as we only have few labels\n",
    "        x = self.conv2(x, edge_index)  # x = (3), update all nodes again, returning (x_size, num_classes)\n",
    "                                       # this final update transforms each node embedding to a class prediction\n",
    "                                       # we do not apply an activation, as the PyTorch CCE calculation\n",
    "                                       # takes care of treating this output as 'softmax'.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nxwb70w6BLzc"
   },
   "outputs": [],
   "source": [
    "## Evaluate the article retrieval system ##\n",
    "model_gnn = GraphSAGE(hidden_channels=16) # initialize our GNN with a hidden size of 16\n",
    "print(model_gnn)\n",
    "\n",
    "# same loss and optimizer as before\n",
    "loss_func = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model_gnn.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train_gnn():\n",
    "    model_gnn.train()  # set the model to training 'mode' (i.e., apply dropout)\n",
    "    optimizer.zero_grad()  # set gradients to 0\n",
    "    out = model_gnn(data_1.x, data_1.edge_index)  # propagate the data through the model\n",
    "    loss = loss_func(out[data_1.train_mask], data_1.y[data_1.train_mask])  # compute the loss based on our training mask\n",
    "    loss.backward()  # derive gradients\n",
    "    optimizer.step()  # update all parameters based on the gradients\n",
    "    return loss\n",
    "\n",
    "def test_gnn(mask):\n",
    "    model_gnn.eval()  # set the model to evaluation 'mode' (don't use dropout)\n",
    "    out = model_gnn(data_1.x, data_1.edge_index)  # propagate the data through the model\n",
    "    pred = out.argmax(dim=1)  # as prediction, we take the class with the highest probability\n",
    "    test_correct = pred[mask] == data_1.y[mask]  # create a tensor that evaluates whether predictions were correct\n",
    "    test_acc = int(test_correct.sum()) / int(mask.sum())  # get the accuracy\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs+1): \n",
    "    loss = train_gnn()  # do one training step over the entire dataset\n",
    "    train_acc = test_gnn(data_1.train_mask)  # compute the training accuracy\n",
    "    test_acc = test_gnn(data_1.test_mask)  # compute the test accuracy\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    train_accs.append(train_acc)  # save accuracies so we can plot them\n",
    "    test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-VtEksc1fCt"
   },
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_-TRngWF1ggw"
   },
   "outputs": [],
   "source": [
    "## Build the anomaly detection model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_ee8w-ZC1jJD"
   },
   "outputs": [],
   "source": [
    "## Download the anomaly evaluation data ##\n",
    "data_2 = download('https://surfdrive.surf.nl/files/index.php/s/EzMkh3SZbsbJb2i/download', filetype='tensor')\n",
    "is_anomaly = download('https://surfdrive.surf.nl/files/index.php/s/wrK5xipcIC9DHhu/download', filetype='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1621940470580,
     "user": {
      "displayName": "Yoeri Poels",
      "photoUrl": "",
      "userId": "12918185417432069249"
     },
     "user_tz": -120
    },
    "id": "IXVaLNjF-mFi",
    "outputId": "0bdf7c85-58f3-4936-ec67-688a160b698a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num new nodes: 2000\n",
      "Num new edges: 50176\n"
     ]
    }
   ],
   "source": [
    "total_node = data_2.x.shape[0]\n",
    "total_edge = data_2.edge_index.shape[1]\n",
    "new_node = total_node - num_node\n",
    "new_edge = total_edge - num_edge\n",
    "print(f'Num new nodes: {new_node}')\n",
    "print(f'Num new edges: {new_edge}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1621940470581,
     "user": {
      "displayName": "Yoeri Poels",
      "photoUrl": "",
      "userId": "12918185417432069249"
     },
     "user_tz": -120
    },
    "id": "8mVXRMxPA_oQ",
    "outputId": "ba3fabfb-e0fb-4351-d6fd-8c26b8e477af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of new nodes are 10701...12700\n",
      "The first 1000 are real articles, the last 1000 are anomaly articles\n",
      "You can use the map \"is_anomaly\" to identify whether a node is an anomaly or not\n",
      "E.g., is_anomaly[11201] = 0 and is_anomaly[12201] = 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Indices of new nodes are {num_node}...{total_node-1}')\n",
    "print('The first 1000 are real articles, the last 1000 are anomaly articles')\n",
    "print('You can use the map \"is_anomaly\" to identify whether a node is an anomaly or not')\n",
    "e_real = num_node+500\n",
    "e_anomaly = num_node+1500\n",
    "print(f'E.g., is_anomaly[{e_real}] = {is_anomaly[e_real]} and is_anomaly[{e_anomaly}] = {is_anomaly[e_anomaly]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzWb42RX1myv"
   },
   "outputs": [],
   "source": [
    "## Evaluate the anomaly detection model ##"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMtIUUNA5rp626+rMGY54T9",
   "collapsed_sections": [],
   "name": "A2_Skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
